[
    {
        "id": "1f10f8b2-7772-3e90-87d4-b984b351d291",
        "title": "Roboticssssss, motor learning, and neurologic recovery.",
        "uri": "http://www.mendeley.com/catalog/robotics-motor-learning-neurologic-recovery/",
        "eexcessURI": "http://www.mendeley.com/catalog/robotics-motor-learning-neurologic-recovery/",
        "creator": "David J Reinkensmeyer, Jeremy L Emken, Steven C Cramer",
        "description": "Robotic devices are helping shed light on human motor control in health and injury. By using robots to apply novel force fields to the arm, investigators are gaining insight into how the nervous system models its external dynamic environment. The nervous system builds internal models gradually by experience and uses them in combination with impedance and feedback control strategies. Internal models are robust to environmental and neural noise, generalized across space, implemented in multiple brain regions, and developed in childhood. Robots are also being used to assist in repetitive movement practice following neurologic injury, providing insight into movement recovery. Robots can haptically assess sensorimotor performance, administer training, quantify amount of training, and improve motor recovery. In addition to providing insight into motor control, robotic paradigms may eventually enhance motor learning and rehabilitation beyond the levels possible with conventional training techniques.",
        "collectionName": "Annual review of biomedical engineering",
        "facets": {
            "provider": "mendeley",
            "year": "2004"
        }
    },
    {
        "id": "7495ea04-aa4e-3a6b-9a6c-4161d4f28ea6",
        "title": "The evolution of robotics research",
        "uri": "http://www.mendeley.com/catalog/evolution-robotics-research/",
        "eexcessURI": "http://www.mendeley.com/catalog/evolution-robotics-research/",
        "creator": "Elena Garcia, Maria Antonia Jimenez, Pablo Gonzalez De Santos, Manuel Armada",
        "description": "This article surveys traditional research topics in industrial robotics and mobile robotics and then expands on new trends in robotics research that focus more on the interaction between human and robot. The new trends in robotics research have been denominated service robotics because of their general goal of getting robots closer to human social needs, and this article surveys research on service robotics such as medical robotics, rehabilitation robotics, underwater robotics, field robotics, construction robotics and humanoid robotics. The aim of this article is to provide an overview of the evolution of research topics in robotics from classical motion control for industrial robots to modern intelligent control techniques and social learning paradigms, among other aspects",
        "collectionName": "IEEE Robotics and Automation Magazine",
        "facets": {
            "provider": "mendeley",
            "year": "2007"
        }
    },
    {
        "id": "6c52238b-367f-3587-8c45-9b1b062ad3d8",
        "title": "Human-robot communication for collaborative decision making - A probabilistic approach",
        "uri": "http://www.mendeley.com/research/humanrobot-communication-collaborative-decision-making-probabilistic-approach/",
        "eexcessURI": "http://www.mendeley.com/research/humanrobot-communication-collaborative-decision-making-probabilistic-approach/",
        "creator": "Tobias Kaupp, Alexei Makarenko, Hugh Durrant-Whyte",
        "description": "Humans and robots need to exchange information if the objective is to achieve a task collaboratively. Two questions are considered in this paper: what and when to communicate. To answer these questions, we developed a human-robot communication framework which makes use of common probabilistic robotics representations. The data stored in the representation determines what to communicate, and probabilistic inference mechanisms determine when to communicate. One application domain of the framework is collaborative human-robot decision making: robots use decision theory to select actions based on perceptual information gathered from their sensors and human operators. In this paper, operators are regarded as remotely located, valuable information sources which need to be managed carefully. Robots decide when to query operators using Value-Of-Information theory, i.e. humans are only queried if the expected benefit of their observation exceeds the cost of obtaining it. This can be seen as a mechanism for adjustable autonomy whereby adjustments are triggered at run-time based on the uncertainty in the robots' beliefs related to their task. This semi-autonomous system is demonstrated using a navigation task and evaluated by a user study. Participants navigated a robot in simulation using the proposed system and via classical teleoperation. Results show that our system has a number of advantages over teleoperation with respect to performance, operator workload, usability, and the users' perception of the robot. We also show that despite these advantages, teleoperation may still be a preferable driving mode depending on the mission priorities. Crown Copyright ?? 2010.",
        "collectionName": "Robotics and Autonomous Systems",
        "facets": {
            "provider": "mendeley",
            "year": "2010"
        }
    },
    {
        "id": "4f99d039-2b7e-3159-a422-a6d9c264ad28",
        "title": "Social interactions in HRI: The robot view",
        "uri": "http://www.mendeley.com/catalog/social-interactions-hri-robot-view/",
        "eexcessURI": "http://www.mendeley.com/catalog/social-interactions-hri-robot-view/",
        "creator": "Cynthia Breazeal",
        "description": "This paper explores the topic of human-robot interaction (HRI) from the perspective of designing sociable autonomous robots - robots designed to interact with people in a human-like way-. There are a growing number of applications for robots that people can engage as capable creatures or as partners rather than tools, yet little is understood about how to best design robots that interact with people in this way. The related field of human-computer interaction (HCI) offers important insights, however autonomous robots are a very different technology from desktop computers. In this paper, we look at the field of HRI from an HCI perspective, pointing out important similarities yet significant differences that may ultimately make HRI a distinct area of inquiry. One outcome of this discussion is that it is important to view the design and evaluation problem from the robot's perspective as well as that of the human. Taken as a whole, this paper provides a framework with which to design and evaluate sociable robots from a HRI perspective.",
        "collectionName": "IEEE Transactions on Systems, Man and Cybernetics Part C: Applications and Reviews",
        "facets": {
            "provider": "mendeley",
            "year": "2004"
        }
    },
    {
        "id": "14053480-ecd3-3374-9566-b78c137cb516",
        "title": "Theory and evaluation of human robot interactions",
        "uri": "http://www.mendeley.com/catalog/theory-evaluation-human-robot-interactions-20/",
        "eexcessURI": "http://www.mendeley.com/catalog/theory-evaluation-human-robot-interactions-20/",
        "creator": "Jean Scholtz",
        "description": "Human-robot interaction (HRI) for mobile robots is still in its infancy. Most user interactions with robots have been limited to tele-operation capabilities where the most common interface provided to the user has been the video feed from the robotic platform and some way of directing the path of the robot. Control systems exhibit autonomy and cognition, and which operate in changing, real-world environments. In addition For mobile robots with semi-autonomous capabilities, the user is also provided with a means of setting way points. More importantly, most HRI capabilities have been developed by robotics experts for use by robotics experts. As robots increase in capabilities and are able to perform more tasks in an autonomous manner we need to think about the interactions that humans will have with robots and what software architecture and user interface designs can accommodate the human in-the-loop. We also need to design systems that can be used by domain experts but not robotics experts. This paper outlines a theory interaction and proposes the interactions of human-robot and information needed by both humans and robots for the different levels of interaction, including an evaluation methodology based on situational awareness.",
        "collectionName": "36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of the",
        "facets": {
            "provider": "mendeley",
            "year": "2003"
        }
    },
    {
        "id": "9d7919af-ac48-312e-ac78-c8880ad0a301",
        "title": "Learning about natural human-robot interaction styles",
        "uri": "http://www.mendeley.com/catalog/learning-about-natural-humanrobot-interaction-styles/",
        "eexcessURI": "http://www.mendeley.com/catalog/learning-about-natural-humanrobot-interaction-styles/",
        "creator": "Tamie Salter, Kerstin Dautenhahn, René Te Boekhorst",
        "description": "If we are to achieve natural human-robot interaction, we may need to complement current vision and speech interfaces. Touch may provide us with an extra tool in this quest. In this paper we demonstrate the role of touch in interaction between a robot and a human. We show how infrared sensors located on robots can be easily used to detect and distinguish human interaction, in this case interaction with individual children. This application of infrared sensors potentially has many uses; for example, in entertainment or service robotics. This system could also benefit therapy or rehabilitation, where the observation and recording of movement and interaction is important. In the long term, this technique might enable robots to adapt to individuals or individual types of user.",
        "collectionName": "Robotics and Autonomous Systems",
        "facets": {
            "provider": "mendeley",
            "year": "2006"
        }
    },
    {
        "id": "8d70f941-335c-389c-9b93-93c059f618c8",
        "title": "Persuasive robotics: The influence of robot gender on human behavior",
        "uri": "http://www.mendeley.com/catalog/persuasive-robotics-influence-robot-gender-human-behavior/",
        "eexcessURI": "http://www.mendeley.com/catalog/persuasive-robotics-influence-robot-gender-human-behavior/",
        "creator": "Mikey Siegel, Cynthia Breazeal, Michael I. Norton",
        "description": "Persuasive Robotics is the study of persuasion as it applies to human-robot interaction (HRI). Persuasion can be generally defined as an attempt to change another's beliefs or behavior. The act of influencing others is fundamental to nearly every type of social interaction. Any agent desiring to seamlessly operate in a social manner will need to incorporate this type of core human behavior. As in human interaction, myriad aspects of a humanoid robot's appearance and behavior can significantly alter its persuasiveness - this work will focus on one particular factor: gender. In the current study, run at the Museum of Science in Boston, subjects interacted with a humanoid robot whose gender was varied. After a short interaction and persuasive appeal, subjects responded to a donation request made by the robot, and subsequently completed a post-study questionnaire. Findings showed that men were more likely to donate money to the female robot, while women showed little preference. Subjects also tended to rate the robot of the opposite sex as more credible, trustworthy, and engaging. In the case of trust and engagement the effect was much stronger between male subjects and the female robot. These results demonstrate the importance of considering robot and human gender in the design of HRI.",
        "collectionName": "2009 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2009",
        "facets": {
            "provider": "mendeley",
            "year": "2009"
        }
    },
    {
        "id": "9042dc56-5cd2-3148-9d81-c1c97e24fd20",
        "title": "A survey of socially interactive robots",
        "uri": "http://www.mendeley.com/catalog/survey-socially-interactive-robots/",
        "eexcessURI": "http://www.mendeley.com/catalog/survey-socially-interactive-robots/",
        "creator": "Terrence Fong, Illah Nourbakhsh, Kerstin Dautenhahn",
        "description": "This paper reviews \"socially interactive robots\": robots for which social human-robot interaction is important. We begin by discussing the context for socially interactive robots, emphasizing the relationship to other research fields and the different forms of \"social robots\". We then present a taxonomy of design methods and system components used to build socially interactive robots. Finally, we describe the impact of these robots on humans and discuss open issues. An expanded version of this paper, which contains a survey and taxonomy of current applications, is available as a technical report [T. Fong, I. Nourbakhsh, K. Dautenhahn, A survey of socially interactive robots: concepts, design and applications, Technical Report No. CMU-RI-TR-02-29, Robotics Institute, Carnegie Mellon University, 2002]. ?? 2003 Elsevier Science B.V. All rights reserved.",
        "collectionName": "Robotics and Autonomous Systems",
        "facets": {
            "provider": "mendeley",
            "year": "2003"
        }
    },
    {
        "id": "34afb763-90b1-392d-badd-6c4df9d42901",
        "title": "A storytelling robot: Modeling and evaluation of human-like gaze behavior",
        "uri": "http://www.mendeley.com/catalog/storytelling-robot-modeling-evaluation-humanlike-gaze-behavior/",
        "eexcessURI": "http://www.mendeley.com/catalog/storytelling-robot-modeling-evaluation-humanlike-gaze-behavior/",
        "creator": "Bilge Mutlu, Jodi Forlizzi, Jessica Hodgins",
        "description": "Engaging storytelling is a necessary skill for humanoid robots if they are to be used in education and entertainment applications. Storytelling requires that the humanoid robot be aware of its audience and able to direct its gaze in a natural way. In this paper, we explore how human gaze can be modeled and implemented on a humanoid robot to create a natural, human-like behavior for storytelling. Our gaze model integrates data collected from a human storyteller and a discourse structure model developed by Cassell and her colleagues for human-like conversational agents (1994). We used this model to direct the gaze of a humanoid robot, Honda's ASIMO, as he recited a Japanese fairy tale using a pre-recorded human voice. We assessed the efficacy of this gaze algorithm by manipulating the frequency of ASIMO's gaze between two participants and used pre and post questionnaires to assess whether participants evaluated the robot more positively and did better on a recall task when ASIMO looked at them more. We found that participants performed significantly better in recalling ASIMO's story when the robot looked at them more. Our results also showed significant differences in how men and women evaluated ASIMO based on the frequency of gaze they received from the robot. Our study adds to the growing evidence that there are many commonalities between human-human communication and human-robot communication",
        "collectionName": "Proceedings of the 2006 6th IEEE-RAS International Conference on Humanoid Robots, HUMANOIDS",
        "facets": {
            "provider": "mendeley",
            "year": "2006"
        }
    },
    {
        "id": "53e108be-a03e-3347-bffc-861d4ea25cae",
        "title": "Natural methods for robot task learning",
        "uri": "http://www.mendeley.com/catalog/natural-methods-robot-task-learning/",
        "eexcessURI": "http://www.mendeley.com/catalog/natural-methods-robot-task-learning/",
        "creator": "Monica N. Nicolescu, Maja J. Mataric",
        "description": "Among humans, teaching various tasks is a complex process which relies on multiple means for interaction and learning, both on the part of the teacher and of the learner. Used together, these modalities lead to effective teaching and learning approaches, respectively. In the robotics domain, task teaching has been mostly addressed by using only one or very few of these interactions. In this paper we present an approach for teaching robots that relies on the key features and the general approach people use when teaching each other: first give a demonstration, then allow the learner to refine the acquired capabilities by practicing under the teacher's supervision, involving a small number of trials. Depending on the quality of the learned task, the teacher may either demonstrate it again or provide specific feedback during the learner's practice trial for further refinement. Also, as people do during demonstrations, the teacher can provide simple instructions and informative cues, increasing the performance of learning. Thus, instructive demonstrations, generalization over multiple demonstrations and practice trials are essential features for a successful human-robot teaching approach. We implemented a system that enables all these capabilities and validated these concepts with a Pioneer 2DX mobile robot learning tasks from multiple demonstrations and teacher feedback.",
        "collectionName": "Proceedings of the Second International Joint Conference on Autonomous Agents and Multiagent systems - AAMAS '03",
        "facets": {
            "provider": "mendeley",
            "year": "2003"
        }
    },
    {
        "id": "4ef8d4ea-8b4a-379d-85af-91b929ffdc57",
        "title": "Can robots be teammates?: Benchmarks in human–robot teams.",
        "uri": "http://www.mendeley.com/catalog/robots-teammates-benchmarks-humanrobot-teams/",
        "eexcessURI": "http://www.mendeley.com/catalog/robots-teammates-benchmarks-humanrobot-teams/",
        "creator": "Victoria Groom, Clifford Nass",
        "description": "The team has become a popular model to organize joint human–robot behavior. Robot teammates are designed with high-levels of autonomy and well-developed coordination skills to aid humans in unpredictable environments. In this paper, we challenge the assumption that robots will succeed as teammates alongside humans. Drawing from the literature on human teams, we evaluate robots’ po- tential to meet the requirements of successful teammates. We argue that lacking humanlike mental models and a sense of self, robots may prove untrustworthy and will be rejected from human teams. Benchmarks for evaluating human–robot teams are included, as are guidelines for defining alternative structures for human–robot groups.",
        "collectionName": "Interaction Studies",
        "facets": {
            "provider": "mendeley",
            "year": "2007"
        }
    },
    {
        "id": "72098366-e5b6-3218-95c4-266ef82258d1",
        "title": "Coordination strategies for multi-robot exploration and mapping",
        "uri": "http://www.mendeley.com/catalog/coordination-strategies-multirobot-exploration-mapping/",
        "eexcessURI": "http://www.mendeley.com/catalog/coordination-strategies-multirobot-exploration-mapping/",
        "creator": "C. Nieto-Granda, J. G. Rogers, H. I. Christensen",
        "description": "Situational awareness in rescue operations can be provided by teams of autonomous mobile robots. Human operators are required to teleoperate the current generation of mobile robots for such applications; however, teleoperation is increasingly difficult as the number of robots is expanded. As the number of robots is increased, each robot may also interfere with one another and eventually decrease mapping performance. As presented here, through careful consideration of robot team coordination and exploration strategy, large numbers of mobile robots can be allocated to accomplish the mapping task more quickly and accurately. We present both the coordination and exploration strategies and present results from experiments in simulation as well as with up to nine mobile platforms.",
        "collectionName": "The International Journal of Robotics Research",
        "facets": {
            "provider": "mendeley",
            "year": "2014"
        }
    },
    {
        "id": "1bedd7a2-6f83-35e4-862d-3f55dcbe2e35",
        "title": "Central pattern generators for locomotion control in animals and robots: A review",
        "uri": "http://www.mendeley.com/catalog/central-pattern-generators-locomotion-control-animals-robots-review/",
        "eexcessURI": "http://www.mendeley.com/catalog/central-pattern-generators-locomotion-control-animals-robots-review/",
        "creator": "Auke Jan Ijspeert",
        "description": "The problem of controlling locomotion is an area in which neuroscience and robotics can fruitfully interact. In this article, I will review research carried out on locomotor central pattern generators (CPGs), i.e. neural circuits capable of producing coordinated patterns of high-dimensional rhythmic output signals while receiving only simple, low-dimensional, input signals. The review will first cover neurobiological observations concerning locomotor CPGs and their numerical modelling, with a special focus on vertebrates. It will then cover how CPG models implemented as neural networks or systems of coupled oscillators can be used in robotics for controlling the locomotion of articulated robots. The review also presents how robots can be used as scientific tools to obtain a better understanding of the functioning of biological CPGs. Finally, various methods for designing CPGs to control specific modes of locomotion will be briefly reviewed. In this process, I will discuss different types of CPG models, the pros and cons of using CPGs with robots, and the pros and cons of using robots as scientific tools. Open research topics both in biology and in robotics will also be discussed. ?? 2008 Elsevier Ltd. All rights reserved.",
        "collectionName": "Neural Networks",
        "facets": {
            "provider": "mendeley",
            "year": "2008"
        }
    },
    {
        "id": "70c29c97-899c-3086-9c29-8a7da9ab9591",
        "title": "Acceptance of healthcare robots for the older population: Review and future directions",
        "uri": "http://www.mendeley.com/catalog/acceptance-healthcare-robots-older-population-review-future-directions/",
        "eexcessURI": "http://www.mendeley.com/catalog/acceptance-healthcare-robots-older-population-review-future-directions/",
        "creator": "E. Broadbent, R. Stafford, B. MacDonald",
        "description": "The rapidly ageing population is placing increasing strain on healthcare services. Robots have been proposed as a way to assist people to stay healthy and safe in their own homes. However, despite the need for such assistive devices and the success of some healthcare robots, other robots have had a poor response. This article reviews the literature about human responses to healthcare robots and summarises the variables that have been found to influence responses. It may be possible to increase acceptance of healthcare robots by properly assessing the needs of the human user and then matching the robot’s role, appearance and behaviour to these needs. Because robots have limitations in their abilities, another way to increase acceptance may be to modify the expectations of users to better match robots’ abilities. More research needs to investigate potential users’ needs and expectations in specific situations and whether interventions to increase the match between robot and human can increase acceptance.",
        "collectionName": "International Journal of Social Robotics",
        "facets": {
            "provider": "mendeley",
            "year": "2009"
        }
    },
    {
        "id": "8846edd2-db8d-3315-a690-6482ef02c323",
        "title": "Surgical robotics",
        "uri": "http://www.mendeley.com/catalog/surgical-robotics-1/",
        "eexcessURI": "http://www.mendeley.com/catalog/surgical-robotics-1/",
        "creator": "Ron Alterovitz, Jaydev P. Desai",
        "description": "Surgical robotics is experiencing an explosion of growth in both academic and clinical settings. Since the first reported robotic surgical procedure two decades ago, surgical robotics has grown into more than a half billion dollar a year industry, and robots are now being used in thousands of surgical procedures each year. One especially successful commercial robot, Intuitive Surgical's da Vinci system for laparoscopic procedures, has been installed worldwide in more than 1,000 locations. This growth is a direct result of the promise of surgical robots to improve patient care. Integration of robot hardware with computer-integrated surgical systems has the potential to enable precise, targeted, minimally invasive medical interventions. Robotic devices are enabling physicians to perform procedures with reduced trauma, less blood loss, fewer errors, and faster patient recovery than would otherwise be possible. Robotics technology can also enhance the effectiveness of clinical procedures by coupling information sources such as medical images to actions in the operating room.",
        "collectionName": "IEEE Robotics and Automation Magazine",
        "facets": {
            "provider": "mendeley",
            "year": "2009"
        }
    },
    {
        "id": "fd94ceab-f501-3b11-9608-e531281436c9",
        "title": "Prediction of human behavior in human-robot interaction using psychological scales for anxiety and negative attitudes toward robots",
        "uri": "http://www.mendeley.com/catalog/prediction-human-behavior-human-robot-interaction-using-psychological-scales-anxiety-negative-attitu/",
        "eexcessURI": "http://www.mendeley.com/catalog/prediction-human-behavior-human-robot-interaction-using-psychological-scales-anxiety-negative-attitu/",
        "creator": "Tatsuya Nomura, Takayuki Kanda, Tomohiro Suzuki, Kensuke Kato",
        "description": "When people interact with communication robots in daily life, their attitudes and emotions toward the robots affect their behavior. From the perspective of robotics design, we need to investigate the influences of these attitudes and emotions on human-robot interaction. This paper reports our empirical study on the relationships between people's attitudes and emotions, and their behavior toward a robot. In particular, we focused on negative attitudes, anxiety, and communication avoidance behavior, which have important implications for robotics design. For this purpose, we used two psychological scales that we had developed: negative attitudes toward robots scale (NARS) and robot anxiety scale (RAS). In the experiment, subjects and a humanoid robot are engaged in simple interactions including scenes of meeting, greeting, self-disclosure, and physical contact. Experimental results indicated that there is a relationship between negative attitudes and emotions, and communication avoidance behavior. A gender effect was also suggested.",
        "collectionName": "IEEE Transactions on Robotics",
        "facets": {
            "provider": "mendeley",
            "year": "2008"
        }
    },
    {
        "id": "9dfe5a8c-7ff4-3081-9736-802de600c1c7",
        "title": "Human mental models of humanoid robots",
        "uri": "http://www.mendeley.com/catalog/human-mental-models-humanoid-robots/",
        "eexcessURI": "http://www.mendeley.com/catalog/human-mental-models-humanoid-robots/",
        "creator": "Sau L. Lee, I. Y M Lau, Sara Kiesler, Chi Y. Chiu",
        "description": "  Effective communication between a person and a robot may depend on whether there exists a common ground of understanding between the two. In two experiments modelled after human-human studies we examined how people form a mental model of a robot&amp;#8217;s factual knowledge. Participants estimated the robot&amp;#8217;s knowledge by extrapolating from their own knowledge and from information about the robot&amp;#8217;s origin and language. These results suggest that designers of humanoid robots must attend not only to the social cues that robots emit but also to the information people use to create mental models of a robot. ",
        "collectionName": "Proceedings - IEEE International Conference on Robotics and Automation",
        "facets": {
            "provider": "mendeley",
            "year": "2005"
        }
    },
    {
        "id": "6c015590-e2bd-391f-a9c0-07d35ff28037",
        "title": "Adaptive LEGO robots. A robot=human view on robotics",
        "uri": "http://www.mendeley.com/catalog/adaptive-lego-robots-robothuman-view-robotics/",
        "eexcessURI": "http://www.mendeley.com/catalog/adaptive-lego-robots-robothuman-view-robotics/",
        "creator": "H.H. Lund, C. Bjerre, J.H. Nielsen, M. Nielsen, K. Stoy",
        "description": "In many applications, robots are viewed as a machine. This has resulted in interaction and actuation which is characteristic for machines. When constructing adaptive LEGO robots, we take another view, namely that the robot should resemble a human (or a biological creature) rather than a machine. This has implications on the interaction, actuation and control of the robot. I describe how the robot-as-human approach is investigated in a number of LEGO Mindstorms robot applications. These include making facial expressions, which allows a LEGO robot to express internal &amp;ldquo;moods&amp;rdquo;, and thereby we might achieve a better human-robot interaction. Another application is the Adaptive LEGO Pet Robot. The Adaptive LEGO Pet Robot's control is based on a modular behaviour system, where a number of the modules are evolved neural networks. Further, the Adaptive LEGO Pet Robot has a number of internal drives such as restlessness and hunger, which allow the robot to react on the internal drives. The human-robot interaction is facilitated by allowing the human to train the LEGO pet robot (rather than to program the robot) to make associations between spoken words (via speech recognition) and evolved behaviour. The Adaptive LEGO Pet Robot is an example of scaling up evolutionary robotics to complex behaviour by combining evolutionary robotics with behaviour-based robotics",
        "collectionName": "IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028)",
        "facets": {
            "provider": "mendeley",
            "year": "1999"
        }
    },
    {
        "id": "00b85ff1-e525-3a0e-9e51-e25da8f14afe",
        "title": "Autonomous robots : from biological inspiration to implementation and control",
        "uri": "http://www.mendeley.com/catalog/autonomous-robots-biological-inspiration-implementation-control/",
        "eexcessURI": "http://www.mendeley.com/catalog/autonomous-robots-biological-inspiration-implementation-control/",
        "creator": "George A Bekey",
        "description": "Autonomous robots are intelligent machines capable of performing tasks in the world by themselves, without explicit human control. Examples range from autonomous helicopters to Roomba, the robot vacuum cleaner. In this book, George Bekey offers an introduction to the science and practice of autonomous robots that can be used both in the classroom and as a reference for industry professionals. He surveys the hardware implementations of more than 300 current systems, reviews some of their application areas, and examines the underlying technology, including control, architectures, learning, manipulation, grasping, navigation, and mapping. Living systems can be considered the prototypes of autonomous systems, and Bekey explores the biological inspiration that forms the basis of many recent developments in robotics. He also discusses robot control issues and the design of control architectures. After an overview of the field that introduces some of its fundamental concepts, the book presents background material on hardware, control (from both biological and engineering perspectives), software architecture, and robot intelligence. It then examines a broad range of implementations and applications, including locomotion (wheeled, legged, flying, swimming, and crawling robots), manipulation (both arms and hands), localization, navigation, and mapping. The many case studies and specific applications include robots built for research, industry, and the military, among them underwater robotic vehicles, walking machines with four, six, and eight legs, and the famous humanoid robots Cog, Kismet, ASIMO, and QRIO. The book concludes with reflections on the future of robotics -- the potential benefits as well as the possible dangers that may arise from large numbers of increasingly intelligent and autonomous robots.",
        "collectionName": "Communication",
        "facets": {
            "provider": "mendeley",
            "year": "2005"
        }
    },
    {
        "id": "1eaeb7ea-0381-357d-b836-daa8028d4a33",
        "title": "Human-robot interaction in rescue robotics",
        "uri": "http://www.mendeley.com/catalog/humanrobot-interaction-rescue-robotics/",
        "eexcessURI": "http://www.mendeley.com/catalog/humanrobot-interaction-rescue-robotics/",
        "creator": "Robin Roberson Murphy",
        "description": "Rescue robotics has been suggested by a recent DARPA/NSF study as an application domain for the research in human-robot integration (HRI). This paper provides a short tutorial on how robots are currently used in urban search and rescue (USAR) and discusses the HRI issues encountered over the past eight years. A domain theory of the search activity is formulated. The domain theory consists of two parts: 1) a workflow model identifying the major tasks, actions, and roles in robot-assisted search (e.g., a workflow model) and 2) a general information flow model of how data from the robot is fused by various team members into information and knowledge. The information flow model also captures the types of situation awareness needed by each agent in the rescue robot system. The article presents a synopsis of the major HRI issues in reducing the number of humans it takes to control a robot, maintaining performance with geographically distributed teams with intermittent communications, and encouraging acceptance within the existing social structure.",
        "collectionName": "IEEE Transactions on Systems, Man and Cybernetics Part C: Applications and Reviews",
        "facets": {
            "provider": "mendeley",
            "year": "2004"
        }
    },
    {
        "id": "40ad8325-d0ef-3743-8b16-a822b77678fe",
        "title": "CONRO: towards deployable robots with inter-robot metamorphic capabilities",
        "uri": "http://www.mendeley.com/catalog/conro-towards-deployable-robots-interrobot-metamorphic-capabilities/",
        "eexcessURI": "http://www.mendeley.com/catalog/conro-towards-deployable-robots-interrobot-metamorphic-capabilities/",
        "creator": "Andres Castano, Wei Min Shen, Peter Will",
        "description": "Metamorphic robots are modular robots that can reconfigure their shape. Such capability is desirable in tasks such as earthquake search and rescue and battlefield surveillance and scouting, where robots must go through unexpected situations and obstacles and perform tasks that are difficult for fixed-shape robots. The capabilities of the robots are determined by the design specification of their modules. In this paper, we present the design specification of a CONRO module, a small, self-sufficient and relatively homogeneous module that can be connected to other modules to form complex robots. These robots have not only the capability of changing their shape (intra-robot metamorphing) but also can split into smaller robots or merge with other robots to create a single larger robot (inter-robot metamorphing), i.e., CONRO robots can alter their shape and their size. Thus, heterogeneous robot teams can be built with homogeneous components. Furthermore, the CONRO robots can separate the reconfiguration stage from the locomotion stage, allowing the selection of configuration-dependent gaits. The locomotion and automatic inter-module docking capabilities of such robots were tested using tethered prototypes that can be reconfigured manually. We conclude the paper discussing the future work needed to fully realize the construction of these robots.",
        "collectionName": "Autonomous Robots",
        "facets": {
            "provider": "mendeley",
            "year": "2000"
        }
    },
    {
        "id": "6c7f91b6-cd77-3aae-88e9-3ebf20b1814b",
        "title": "A two-tiered global path planning strategy for limited memory mobile robots",
        "uri": "http://www.mendeley.com/catalog/twotiered-global-path-planning-strategy-limited-memory-mobile-robots/",
        "eexcessURI": "http://www.mendeley.com/catalog/twotiered-global-path-planning-strategy-limited-memory-mobile-robots/",
        "creator": "Praneel Chand, Dale A. Carnegie",
        "description": "Multi-robot systems have inherent advantages such as the ability to allocate and redistribute tasks across the team of robots. For multi-robot tasks such as exploration of large environments, some of the available robots may only possess simple embedded controllers with limited memory capacity. However, in some situations these limited robots may be required to perform global path planning to navigate beyond localised regions of the large environment. Global path planning can be problematic for the limited memory robots if they are unable to store the entire map in their local memory. Hence, this paper presents and evaluates a two-tiered path planning technique to permit global path planning. A set of local maps describing the global map is searched using a two-tiered A* algorithm that executes entirely on the limited memory robots. Planning time, data communication and path length are evaluated for various combinations of local and global maps. Employing smaller local map sizes in large global maps is capable of yielding superior or comparable execution times to non-memory constrained planning. ?? 2011 Elsevier B.V. All rights reserved.",
        "collectionName": "Robotics and Autonomous Systems",
        "facets": {
            "provider": "mendeley",
            "year": "2012"
        }
    },
    {
        "id": "8cb36c03-075a-3b45-9143-d924ff92e633",
        "title": "Fitness functions in evolutionary robotics: A survey and analysis",
        "uri": "http://www.mendeley.com/catalog/fitness-functions-evolutionary-robotics-survey-analysis/",
        "eexcessURI": "http://www.mendeley.com/catalog/fitness-functions-evolutionary-robotics-survey-analysis/",
        "creator": "Andrew L. Nelson, Gregory J. Barlow, Lefteris Doitsidis",
        "description": "This paper surveys fitness functions used in the field of evolutionary robotics (ER). Evolutionary robotics is a field of research that applies artificial evolution to generate control systems for autonomous robots. During evolution, robots attempt to perform a given task in a given environment. The controllers in the better performing robots are selected, altered and propagated to perform the task again in an iterative process that mimics some aspects of natural evolution. A key component of this process-one might argue, the key component-is the measurement of fitness in the evolving controllers. ER is one of a host of machine learning methods that rely on interaction with, and feedback from, a complex dynamic environment to drive synthesis of controllers for autonomous agents. These methods have the potential to lead to the development of robots that can adapt to uncharacterized environments and which may be able to perform tasks that human designers do not completely understand. In order to achieve this, issues regarding fitness evaluation must be addressed. In this paper we survey current ER research and focus on work that involved real robots. The surveyed research is organized according to the degree of a priori knowledge used to formulate the various fitness functions employed during evolution. The underlying motivation for this is to identify methods that allow the development of the greatest degree of novel control, while requiring the minimum amount of a priori task knowledge from the designer. ?? 2008 Elsevier B.V. All rights reserved.",
        "collectionName": "Robotics and Autonomous Systems",
        "facets": {
            "provider": "mendeley",
            "year": "2009"
        }
    },
    {
        "id": "cacd96a9-2489-3ab9-9801-befef8b5848b",
        "title": "Introduction to Autonomous Mobile Robots",
        "uri": "http://www.mendeley.com/catalog/introduction-autonomous-mobile-robots-50/",
        "eexcessURI": "http://www.mendeley.com/catalog/introduction-autonomous-mobile-robots-50/",
        "creator": "Roland Siegwart, Illah R Nourbakhsh",
        "description": "Mobile robots range from the teleoperated Sojourner on the Mars Pathfinder mission to cleaning robots in the Paris Metro. Introduction to Autonomous Mobile Robots offers students and other interested readers an overview of the technology of mobility the mechanisms that allow a mobile robot to move through a real world environment to perform its tasksincluding locomotion, sensing, localization, and motion planning. It discusses all facets of mobile robotics, including hardware design, wheel design, kinematics analysis, sensors and perception, localization, mapping, and robot control architectures.The design of any successful robot involves the integration of many different disciplines, among them kinematics, signal analysis, information theory, artificial intelligence, and probability theory. Reflecting this, the book presents the techniques and technology that enable mobility in a series of interacting modules. Each chapter covers a different aspect of mobility, as the book moves from low-level to high-level details. The first two chapters explore low-level locomotory ability, examining robots' wheels and legs and the principles of kinematics. This is followed by an in-depth view of perception, including descriptions of many \"off-the-shelf\" sensors and an analysis of the interpretation of sensed data. The final two chapters consider the higher-level challenges of localization and cognition, discussing successful localization strategies, autonomous mapping, and navigation competence. Bringing together all aspects of mobile robotics into one volume, Introduction to Autonomous Mobile Robots can serve as a textbook for coursework or a working tool for beginners in the field.",
        "collectionName": "Robotica",
        "facets": {
            "provider": "mendeley",
            "year": "2004"
        }
    },
    {
        "id": "27d8886d-a4be-3554-8a39-0c1451e5818f",
        "title": "Adaptive navigation for autonomous robots",
        "uri": "http://www.mendeley.com/catalog/adaptive-navigation-autonomous-robots/",
        "eexcessURI": "http://www.mendeley.com/catalog/adaptive-navigation-autonomous-robots/",
        "creator": "Matt Knudson, Kagan Tumer",
        "description": "In many robotic exploration missions, robots have to learn specific policies that allow them to: (i) select high level goals (e.g., identify specific destinations), (ii) navigate (reach those destinations), (iii) and adapt to their environment (e.g., modify their behavior based on changing environmental conditions). Furthermore, those policies must be robust to signal noise or unexpected situations, scalable to more complex environments, and account for the physical limitations of the robots (e.g., limited battery power and computational power). In this paper we evaluate reactive and learning navigation algorithms for exploration robots that must avoid obstacles and reach specific destinations in limited time and with limited observations. Our results show that neuro-evolutionary algorithms with well-designed evaluation functions can produce up to 50% better performance than reactive algorithms in complex domains where the robot's goals are to select paths that lead to seek specific destinations while avoiding obstacles, particularly when facing significant sensor and actuator signal noise. ?? 2011 Elsevier B.V. All rights reserved.",
        "collectionName": "Robotics and Autonomous Systems",
        "facets": {
            "provider": "mendeley",
            "year": "2011"
        }
    },
    {
        "id": "33c4e6a4-4587-3188-b7ca-42addf007c74",
        "title": "Reem-B: An autonomous lightweight human-size humanoid robot",
        "uri": "http://www.mendeley.com/catalog/reemb-autonomous-lightweight-humansize-humanoid-robot/",
        "eexcessURI": "http://www.mendeley.com/catalog/reemb-autonomous-lightweight-humansize-humanoid-robot/",
        "creator": "Ricardo Tellez, Francesco Ferro, Sergio Garcia, Esteban Gomez, Enric Jorge, Dario Mora, Daniel Pinyol, Joan Oliver, Oriol Torres, Jorge Velazquez, Davide Faconti",
        "description": "This paper introduces the humanoid robot Reem-B, built by Pal robotics as a research platform in the field of service robots. The idea is to produce robots that can help humans and cohabit their environments. For this purpose, the body plan, sensory and actuator system of the robot, as well as its cognitive abilities must be designed to perform real-world tasks including dynamic walking, interaction with people or object recognition and manipulation. Reem-B achieves this scope by using two legs, two strong arms with fingered hands, and a software suite that controls all its degrees of freedom, coordinating them with vision and auditory systems. The main difference with other humanoids of its size is its level of autonomy. Autonomy in this robot has been improved from other robots at three different levels: with an increased battery life (estimated twice of the competitors), with the ability to autonomously navigate in indoor environments while avoiding obstacles, and by integrating all the control systems within the robot itself.",
        "collectionName": "2008 8th IEEE-RAS International Conference on Humanoid Robots, Humanoids 2008",
        "facets": {
            "provider": "mendeley",
            "year": "2008"
        }
    },
    {
        "id": "31426089-8a0a-34ee-a0d5-87c10bf76eab",
        "title": "An architecture for cooperative and autonomous mobile robots",
        "uri": "http://www.mendeley.com/catalog/architecture-cooperative-autonomous-mobile-robots/",
        "eexcessURI": "http://www.mendeley.com/catalog/architecture-cooperative-autonomous-mobile-robots/",
        "creator": "F.R. Noreils",
        "description": "The author describes an architecture for cooperative and autonomous mobile robots. The cooperation is composed of two phases: collaboration where a task is decomposed into subtasks and subtasks are allocated through a set of robots, and coordination where robots actually coordinate their activities to fulfil the initial task using the notion of coordinated protocols. This architecture exhibits benefits such as (1) modularity (the robot can work autonomously or within a team); (2) robustness (although some modules on the robot fail, it is still able to perform useful tasks); and (3) programmability. An example using two real robots is described to show the approach",
        "collectionName": "Proceedings 1992 IEEE International Conference on Robotics and Automation",
        "facets": {
            "provider": "mendeley",
            "year": "1992"
        }
    },
    {
        "id": "0fc99ddb-887c-3359-88c0-adb823da9c45",
        "title": "Real time gait generation for autonomous humanoid robots: A case study for walking",
        "uri": "http://www.mendeley.com/catalog/real-time-gait-generation-autonomous-humanoid-robots-case-study-walking/",
        "eexcessURI": "http://www.mendeley.com/catalog/real-time-gait-generation-autonomous-humanoid-robots-case-study-walking/",
        "creator": "Genci Capi, Yasuo Nasu, Leonard Barolli, Kazuhitsa Mitobe",
        "description": "As autonomous humanoid robots assume more important roles in everyday life, they are expected to perform many different tasks and quickly adapt to unknown environments. Therefore, humanoid robots must generate quickly the appropriate gait based on information received from visual system. In this work, we present a new method for real time gait generation during walking based on Neural Networks. The minimum consumed energy gaits similar with human motion, are used to teach the Neural Network. After supervised learning, the Neural Network can quickly generate the humanoid robot gait. Simulation and experimental results utilizing the \"Bonten-Maru I\" humanoid robot show good performance of the proposed method. ?? 2002 Elsevier Science B.V. All rights reserved.",
        "collectionName": "Robotics and Autonomous Systems",
        "facets": {
            "provider": "mendeley",
            "year": "2003"
        }
    },
    {
        "id": "5f1f989e-285d-3f2a-8147-f89b26f5cd5b",
        "title": "Self-assembly on demand in a group of physical autonomous mobile robots navigating rough terrain",
        "uri": "http://www.mendeley.com/catalog/selfassembly-demand-group-physical-autonomous-mobile-robots-navigating-rough-terrain/",
        "eexcessURI": "http://www.mendeley.com/catalog/selfassembly-demand-group-physical-autonomous-mobile-robots-navigating-rough-terrain/",
        "creator": "Rehan O'Grady, Roderich Groß, Francesco Mondada, Michael Bonani, Marco Dorigo",
        "description": "Consider a group of autonomous, mobile robots with the ability to physically connect to one another (self-assemble). The group is said to exhibit functional self-assembly if the robots can choose to self-assemble in response to the demands of their task and environment. We present the first robotic controller capable of functional self-assembly implemented on a real robotic platform. The task we consider requires a group of robots to navigate over an area of unknown terrain towards a target light source. If possible, the robots should navigate to the target independently. If, however, the terrain proves too difficult for a single robot, the robots should self-assemble into a larger group entity and collectively navigate to the target. We believe this to be one of the most complex tasks carried out to date by a team of physical autonomous robots. We present quantitative results confirming the efficacy of our controller. This puts our robotic system at the cutting edge of autonomous mobile multi-robot research.",
        "collectionName": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "facets": {
            "provider": "mendeley",
            "year": "2005"
        }
    },
    {
        "id": "220f6b4b-cf7f-3860-abd5-f4688cd4727f",
        "title": "Autonomous driving in a multi-level parking structure",
        "uri": "http://www.mendeley.com/catalog/autonomous-driving-multilevel-parking-structure/",
        "eexcessURI": "http://www.mendeley.com/catalog/autonomous-driving-multilevel-parking-structure/",
        "creator": "Rainer Kümmerle, Dirk Hähnel, Dmitri Dolgov, Sebastian Thrun, Wolfram Burgard",
        "description": "Recently, the problem of autonomous navigation of automobiles has gained substantial interest in the robotics community. Especially during the two recent DARPA grand challenges, autonomous cars have been shown to robustly navigate over extended periods of time through complex desert courses or through dynamic urban traffic environments. In these tasks, the robots typically relied on GPS traces to follow pre-defined trajectories so that only local planners were required. In this paper, we present an approach for autonomous navigation of cars in indoor structures such as parking garages. Our approach utilizes multi-level surface maps of the corresponding environments to calculate the path of the vehicle and to localize it based on laser data in the absence of sufficiently accurate GPS information. It furthermore utilizes a local path planner for controlling the vehicle. In a practical experiment carried out with an autonomous car in a real parking garage we demonstrate that our approach allows the car to autonomously park itself in a large-scale multi-level structure.",
        "collectionName": "Proceedings - IEEE International Conference on Robotics and Automation",
        "facets": {
            "provider": "mendeley",
            "year": "2009"
        }
    },
    {
        "id": "4bf6ee17-bc2a-3c22-a1ba-63973406b22d",
        "title": "Autonomous manipulation with a general-purpose simple hand",
        "uri": "http://www.mendeley.com/catalog/autonomous-manipulation-generalpurpose-simple-hand/",
        "eexcessURI": "http://www.mendeley.com/catalog/autonomous-manipulation-generalpurpose-simple-hand/",
        "creator": "M. T. Mason, A. Rodriguez, S. S. Srinivasa, A. S. Vazquez",
        "description": "While complex hands seem to offer generality, simple hands are often more practical. This raises the question: how do generality and simplicity trade off in the design of robot hands? This paper explores the tension between simplicity in hand design and generality in hand function. It raises arguments both for and against simple hands, it considers several familiar examples, and it proposes an approach for autonomous manipulation using a general-purpose but simple hand.We explore the approach in the context of a bin-picking task, focused on grasping, recognition, and localization. The central idea is to use learned knowledge of stable grasp poses as a cue for object recognition and localization. This leads to some novel design criteria, such as minimizing the number of stable grasp poses. Finally, we describe experiments with two prototype hands to perform bin-picking of highlighter markers.",
        "collectionName": "The International Journal of Robotics Research",
        "facets": {
            "provider": "mendeley",
            "year": "2012"
        }
    },
    {
        "id": "4bb17ab2-df59-391e-a244-91b3149b1b65",
        "title": "A general-purpose method for decision-making in autonomous robots",
        "uri": "http://www.mendeley.com/research/generalpurpose-method-decisionmaking-autonomous-robots/",
        "eexcessURI": "http://www.mendeley.com/research/generalpurpose-method-decisionmaking-autonomous-robots/",
        "creator": "Mattias Wahde",
        "description": "In this paper, it is argued that the standard taxonomy of behavior selection is incomplete. In order to overcome the limitations of standard behavior selection, a novel method for decision-making, the extended utility function (EUF) method, has been developed. Based on the concept of utility as a common currency for decision-making, the method handles decision-making involving both cognitive processes and (motor) behaviors, and is applicable as a general-purpose framework for decision-making in autonomous robots (as well as software agents). The EUF method is introduced and described, and it is then illustrated by means of an example. Preliminary tests indicate that the method per- forms well, allowing users rapidly to set up a decision-making system.",
        "collectionName": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "facets": {
            "provider": "mendeley",
            "year": "2009"
        }
    },
    {
        "id": "6dfc7297-c206-3b5d-a78d-249ff1eda690",
        "title": "Individual and cooperative tasks performed by autonomous MAV teams driven by embodied neural network controllers",
        "uri": "http://www.mendeley.com/catalog/individual-cooperative-tasks-performed-autonomous-mav-teams-driven-embodied-neural-network-controlle/",
        "eexcessURI": "http://www.mendeley.com/catalog/individual-cooperative-tasks-performed-autonomous-mav-teams-driven-embodied-neural-network-controlle/",
        "creator": "Fabio Ruini, Angelo Cangelosi, Franck Zetule",
        "description": "The work presented here focuses on the use of embodied neural network controllers for MAV (micro-unmanned aerial vehicles) teams. The computer model we have built aims to demonstrate how autonomous controllers for groups of flying robots can be successfully developed through simulations based on multi-agent systems and evolutionary robotics methodologies. We first introduce the field of autonomous flying robots, reviewing the most relevant contributes on this research field and highlighting the elements of novelty contained in our approach. We then describe the simulation model we have elaborated and the results obtained in different experimental scenarios. In all experiments, MAV teams made by four agents have to navigate autonomously through an unknown environment, reach a certain target and finally neutralize it through a self-detonation. The different setups comprise an environment with various obstacles (skyscrapers) and a fixed target, one with a moving target, and one where the target (fixed or moving) needs to be attacked cooperatively in order to be neutralized. The results obtained show how the evolved controllers are able to perform the various tasks with an accuracy level between 72% and 94% when the target has to be approached individually. The performance slightly decreases only when the target is both able to move and can only be neutralized through a coordinated operation. The paper ends with a discussion on the possible applications of autonomous MAV teams to real life scenarios.",
        "collectionName": "Proceedings of the International Joint Conference on Neural Networks",
        "facets": {
            "provider": "mendeley",
            "year": "2009"
        }
    },
    {
        "id": "0b6ba308-2737-3601-95cc-a5855057546f",
        "title": "Multi-agent robot systems as distributed autonomous systems",
        "uri": "http://www.mendeley.com/catalog/multiagent-robot-systems-distributed-autonomous-systems-4/",
        "eexcessURI": "http://www.mendeley.com/catalog/multiagent-robot-systems-distributed-autonomous-systems-4/",
        "creator": "Jun Ota",
        "description": "In the numerous existing studies dealing with multi-agent robot systems, the systems are positioned on the crossover area of robotics and distributed autonomous systems. Multi-agent robots perform many tasks, which are classified into six types according to the dimension of the goal state and the number of iterations of the tasks. This paper surveys earlier studies on multi-agent robots for each type, such as multi-robot motion-planning algorithms and exploration algorithms of multiple robots. The tasks that multi-agent robots can perform are becoming increasingly more complex as they move from single, one-time tasks to those involving many iterations. This study is an investigation of the current trends and the potentials for multi-agent robot systems. ?? 2005 Elsevier Ltd. All rights reserved.",
        "collectionName": "Advanced Engineering Informatics",
        "facets": {
            "provider": "mendeley",
            "year": "2006"
        }
    },
    {
        "id": "e50fc99b-23af-3dde-b4be-5e7ef4b8ccde",
        "title": "Multi-Touch Interface for Controlling Multiple Mobile Robots",
        "uri": "http://www.mendeley.com/catalog/multitouch-interface-controlling-multiple-mobile-robots/",
        "eexcessURI": "http://www.mendeley.com/catalog/multitouch-interface-controlling-multiple-mobile-robots/",
        "creator": "Jun Kato, Daisuke Sakamoto, Masahiko Inami, Takeo Igarashi",
        "description": "We must give some form of a command to robots in order to have the robots do a complex task. An initial instruction is required even if they do their tasks autonomously. We therefore need interfaces for the operation and teaching of robots. Natural languages, joysticks, and other pointing devices are currently used for this purpose. These interfaces, however, have difficulty in operating multiple robots simultaneously. We developed a multi-touch interface with a top-down view from a ceiling camera for controlling multiple mobile robots. The user specifies a vector field followed by all robots on the view. This paper describes the user interface and its implementation, and future work of the project.",
        "collectionName": "Proceedings of the 27th",
        "facets": {
            "provider": "mendeley",
            "year": "2009"
        }
    },
    {
        "id": "4060559a-9a90-33b6-9f19-5fc7f913cc62",
        "title": "The Advisor Robot: Tracing People’s Mental Model from a Robot’s Physical Attributes",
        "uri": "http://www.mendeley.com/catalog/advisor-robot-tracing-peoples-mental-model-robots-physical-attributes/",
        "eexcessURI": "http://www.mendeley.com/catalog/advisor-robot-tracing-peoples-mental-model-robots-physical-attributes/",
        "creator": "Aaron Powers, Aaron Powers, Sara Kiesler, Sara Kiesler",
        "description": " Humanoid robots offer many physical design choices such as voice frequency and head dimensions. We used hierarchical statistical mediation analysis to trace differences in people's mental model of robots from these choices. In an experiment, a humanoid robot gave participants online advice about their health. We used mediation analysis to identify the causal path from the robot's voice and head dimensions to the participants' mental model, and to their willingness to follow the robot's advice. The male robot voice predicted impressions of a knowledgeable robot, whose advice participants said they would follow. Increasing the voice's fundamental frequency reduced this effect. The robot's short chin length (but not its forehead dimensions) predicted impressions of a sociable robot, which also predicted intentions to take the robot's advice. We discuss the use of this approach for designing robots for different roles, when people's mental model of the robot matters. ",
        "collectionName": "HRI '06: Proceedings of the 1st ACM SIGCHI/SIGART Conference on Human-Robot Interaction",
        "facets": {
            "provider": "mendeley",
            "year": "2006"
        }
    },
    {
        "id": "a556304a-b837-3788-8eff-6dd7f3b3742e",
        "title": "Human-centered robot navigation - Toward a harmoniously coexisting multi-human and multi-robot environment",
        "uri": "http://www.mendeley.com/catalog/humancentered-robot-navigation-toward-harmoniously-coexisting-multihuman-multirobot-environment/",
        "eexcessURI": "http://www.mendeley.com/catalog/humancentered-robot-navigation-toward-harmoniously-coexisting-multihuman-multirobot-environment/",
        "creator": "Chi Pang Lam, Chen Tun Chou, Chih Fu Chang, Li Chen Fu",
        "description": "This paper proposes a navigation algorithm that considers the states of humans and other robots in order to achieve harmonious coexistence between robots and humans. When navigating through humans and robots with different functions, a robot should not only pay attention to obstacle avoidance and goal seeking, it should also take care of whether it interferes with other people or robots. To deal with this problem, we propose several harmonious rules, which guarantee a safe and smooth navigation in multi-human and multi-robot (MHMR) environment. Based on those rules, a practical navigation method - human-centered sensitive navigation (HCSN) - is proposed. HCSN considers the fact that both humans and robots have sensitive zones depending on their security regions or on psychological feeling of people. We model these zones as various sensitive fields with priorities, whereby robots tend to yield socially acceptable movements.",
        "collectionName": "IEEE/RSJ 2010 International Conference on Intelligent Robots and Systems, IROS 2010 - Conference Proceedings",
        "facets": {
            "provider": "mendeley",
            "year": "2010"
        }
    },
    {
        "id": "4a310d4d-97e9-3ff0-b38a-9539111788fb",
        "title": "Programming by touch: The different way of human-robot interaction",
        "uri": "http://www.mendeley.com/catalog/programming-touch-different-way-humanrobot-interaction/",
        "eexcessURI": "http://www.mendeley.com/catalog/programming-touch-different-way-humanrobot-interaction/",
        "creator": "Gerhard Grunwald, Günter Schreiber, Alin Albu-Schäffer, Gerd Hirzinger",
        "description": "Mobile service robots will share their workspaces, e.g., offices, hospitals, or households, with humans. Thus, a direct contact between man and machine is inevitable. Robots equipped with appropriate sensors can sense the touch. In this paper, we present how an unskilled user can intuitively teach the lightweight robot at the German Aerospace Center (DLR), We&amp;szlig;ling, Germany, just by touching the arm. Programming by \"touch\" is very intuitive as you take the robot by the hand and demonstrate the movements. This feature can also be used to interact with the service robot while executing a task. Therefore, if our seven-degrees-of-freedom robot arm senses a touch, it will react by an evasive motion of the touched links while keeping the orientation of the tool center point.",
        "collectionName": "IEEE Transactions on Industrial Electronics",
        "facets": {
            "provider": "mendeley",
            "year": "2003"
        }
    },
    {
        "id": "e527e8f7-5efc-31a2-bfc1-3b3c02bc971d",
        "title": "Evolutionary role model and basic emotions of service robots originated from computers",
        "uri": "http://www.mendeley.com/research/evolutionary-role-model-basic-emotions-service-robots-originated-computers/",
        "eexcessURI": "http://www.mendeley.com/research/evolutionary-role-model-basic-emotions-service-robots-originated-computers/",
        "creator": "Jeonghye Han Jeonghye Han, Jaeyeon Lee Jaeyeon Lee, Youngjo Cho Youngjo Cho",
        "description": " This paper proposes an evolutionary role model for service robots with LCD touch panels such as home robots, and suggests the necessity of reestablishment of robot emotions on the basis of the new role model. The typical HRI-based peer role model is appropriate for the android, the future intelligent robot, but it failed to take into account the state of temporary robotics. In this study, a role model was proposed by allowing for the evolutionary aspects in step with the level of robot technology. Also, the feasibility of the proposed evolutionary role model was demonstrated through the experiments after parents and children interacted with a home robot that had various functions for family members. The results showed that the expected roles of home robots are user, secretary, and peer. Most of parents thought of them as human-like machines while children regarded them as peers. Home robot's facial expressions depend on their roles. So, we investigated the facial expression set of home robots at work and compared them with Ekman's. We also hypothesized that if the facial expression set for a home robot at work is different from the expected one, it had a significant impact on evaluation. The results suggested the necessity of new modelling of facial expressions for home robots based on the evolutionary role model.",
        "collectionName": "ROMAN 2005. IEEE International Workshop on Robot and Human Interactive Communication, 2005.",
        "facets": {
            "provider": "mendeley",
            "year": "2005"
        }
    },
    {
        "id": "4bcc8b98-f36f-3129-862f-41b280265c4a",
        "title": "Collaborative multi-robot exploration",
        "uri": "http://www.mendeley.com/catalog/collaborative-multirobot-exploration/",
        "eexcessURI": "http://www.mendeley.com/catalog/collaborative-multirobot-exploration/",
        "creator": "W. Burgard, M. Moors, D. Fox, R. Simmons, S. Thrun",
        "description": "In this paper we consider the problem of exploring an unknown environment by a team of robots. As in single-robot exploration the goal is to minimize the overall exploration time. The key problem to be solved therefore is to choose appropriate target points for the individual robots so that they simultaneously explore different regions of their environment. We present a probabilistic approach for the coordination of multiple robots which, in contrast to previous approaches, simultaneously takes into account the costs of reaching a target point and the utility of target points. The utility of target points is given by the size of the unexplored area that a robot can cover with its sensors upon reaching a target position. Whenever a target point is assigned to a specific robot, the utility of the unexplored area visible from this target position is reduced for the other robots. This way, a team of multiple robots assigns different target points to the individual robots. The technique has been implemented and tested extensively in real-world experiments and simulation runs. The results given in this paper demonstrate that our coordination technique significantly reduces the exploration time compared to previous approaches",
        "collectionName": "Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065)",
        "facets": {
            "provider": "mendeley",
            "year": "2000"
        }
    },
    {
        "id": "e20e4b7d-f231-30d3-80f3-245a320a2dee",
        "title": "Coordinated multi-robot exploration",
        "uri": "http://www.mendeley.com/catalog/coordinated-multirobot-exploration/",
        "eexcessURI": "http://www.mendeley.com/catalog/coordinated-multirobot-exploration/",
        "creator": "Wolfram Burgard, Mark Moors, Cyrill Stachniss, Frank E. Schneider",
        "description": " In this paper, we consider the problem of exploring an unknown environment with a team of robots. As in single-robot exploration the goal is to minimize the overall exploration time. The key problem to be solved in the context of multiple robots is to choose appropriate target points for the individual robots so that they simultaneously explore different regions of the environment. We present an approach for the coordination of multiple robots, which simultaneously takes into account the cost of reaching a target point and its utility. Whenever a target point is assigned to a specific robot, the utility of the unexplored area visible from this target position is reduced. In this way, different target locations are assigned to the individual robots. We furthermore describe how our algorithm can be extended to situations in which the communication range of the robots is limited. Our technique has been implemented and tested extensively in real-world experiments and simulation runs. The results demonstrate that our technique effectively distributes the robots over the environment and allows them to quickly accomplish their mission.",
        "collectionName": "IEEE Transactions on Robotics",
        "facets": {
            "provider": "mendeley",
            "year": "2005"
        }
    },
    {
        "id": "d8a8c10b-69f3-388a-adc9-ed0331bc40a9",
        "title": "Discussion of Challenges for User Interfaces in Human-Robot Teams",
        "uri": "http://www.mendeley.com/research/discussion-challenges-user-interfaces-humanrobot-teams/",
        "eexcessURI": "http://www.mendeley.com/research/discussion-challenges-user-interfaces-humanrobot-teams/",
        "creator": "F Driewer, M Sauer, K Schilling",
        "description": "This paper describes the challenges for user interfaces in human-robot teams and elaborates requirements considering the different roles that human can take over in such teams. The implementation of various test interfaces and observations from experiments support the claimed requirements. The discussed human-robot teams consist of a remote supervisor and several team members (humans and robots) in the workspace. Humans and robots incorporate their different capabilities into the team for the accomplishment of a common goal. The supervisor guides the team and monitors the overall situation. The humans in the workspace work side-by-side with the robots and interact with them as peers. \nIndex Terms  Human-robot interaction (HRI), Human-robot teams, teleoperation, user interfaces.",
        "collectionName": "ECMR 2007",
        "facets": {
            "provider": "mendeley",
            "year": "2007"
        }
    },
    {
        "id": "2102f60d-8673-33ae-963e-1f0d76e62ef4",
        "title": "Human-centered robot navigation-towards a harmoniously human-robot coexisting environment",
        "uri": "http://www.mendeley.com/catalog/humancentered-robot-navigationtowards-harmoniously-humanrobot-coexisting-environment/",
        "eexcessURI": "http://www.mendeley.com/catalog/humancentered-robot-navigationtowards-harmoniously-humanrobot-coexisting-environment/",
        "creator": "Chi Pang Lam, Chen Tun Chou, Kuo Hung Chiang, Li Chen Fu",
        "description": "This paper proposes a navigation algorithm that considers the states of humans and robots in order to achieve harmonious coexistence between them. A robot navigation in the presence of humans and other robots is rarely considered in the field of robotics. When navigating through a space filled with humans and robots with different functions, a robot should not only pay attention to obstacle avoidance and goal seeking, it should also take into account whether it interferes with other people or robots. To deal with this problem, we propose several harmonious rules, which guarantee a safe and smooth navigation in a human-robot environment. Based on these rules, a practical navigation method \"human-centered sensitive navigation (HCSN)\" is proposed. HCSN considers the fact that both humans and robots have sensitive zones, depending on their security regions or on a human's psychological state. We model these zones as various sensitive fields with priorities, whereby robots tend to yield socially acceptable movements.",
        "collectionName": "IEEE Transactions on Robotics",
        "facets": {
            "provider": "mendeley",
            "year": "2011"
        }
    },
    {
        "id": "20520596-3695-3c09-ae3b-cc191fcd919b",
        "title": "A General-Purpose 7 DOF Haptic Device: Applications Toward Robot-Assisted Surgery",
        "uri": "http://www.mendeley.com/catalog/generalpurpose-7-dof-haptic-device-applications-toward-robotassisted-surgery/",
        "eexcessURI": "http://www.mendeley.com/catalog/generalpurpose-7-dof-haptic-device-applications-toward-robotassisted-surgery/",
        "creator": "G. Tholey, J.P. Desai",
        "description": "A 7 DOF haptic device has been designed and developed with applications towards robot-assisted minimally invasive surgery. The device consists of four degrees of force feedback (X, Y, Z, and grasping) capability and seven degrees of position feedback capability. It has a closed kinematic chain with two halves (user interface and spatial mechanism) that connect together via a universal joint. The user interface contains four degrees of position feedback, namely, the roll, pitch, yaw, and linear motion of the hand and forearm. In addition, a grasping mechanism with two thimbles mounted at the end of the user interface provides force feedback to the fingers of the user. The spatial mechanism provides force feedback to the user interface through a universal joint located at the grasping mechanism. This paper presents the design and development of this haptic device. In addition, a kinematic and workspace analysis of the device has been completed to compute the position of the slave robot and end-effector tool. Friction estimation has been presented to enable a higher transparency of the haptic device. Finally, a simulation of needle insertion into soft tissue was developed to test the device.",
        "collectionName": "IEEE/ASME Transactions on Mechatronics",
        "facets": {
            "provider": "mendeley",
            "year": "2007"
        }
    },
    {
        "id": "c22dec5e-ed01-3057-aac4-d1faa8487e77",
        "title": "Learning to fall: Designing low damage fall sequences for humanoid soccer robots",
        "uri": "http://www.mendeley.com/catalog/learning-fall-designing-low-damage-fall-sequences-humanoid-soccer-robots/",
        "eexcessURI": "http://www.mendeley.com/catalog/learning-fall-designing-low-damage-fall-sequences-humanoid-soccer-robots/",
        "creator": "J. Ruiz-del-Solar, R. Palma-Amestoy, R. Marchant, I. Parra-Tsunekawa, P. Zegers",
        "description": "A methodology for the analysis and design of fall sequences of robots that minimize joint/articulation injuries, and the damage of valuable body parts is proposed. These fall sequences can be activated/triggered by the robot in case of a detected unintentional fall or an intentional fall, which are common events in humanoid soccer environments. The methodology is human-based and requires the use of a realistic simulator as development tool. The obtained results show that fall sequences designed using the proposed method produce less damage than standard, uncontrolled falls. ?? 2009 Elsevier B.V. All rights reserved.",
        "collectionName": "Robotics and Autonomous Systems",
        "facets": {
            "provider": "mendeley",
            "year": "2009"
        }
    },
    {
        "id": "6f53637f-faed-3276-b5d6-1a89f8644515",
        "title": "Domo: a force sensing humanoid robot for manipulation research",
        "uri": "http://www.mendeley.com/catalog/domo-force-sensing-humanoid-robot-manipulation-research/",
        "eexcessURI": "http://www.mendeley.com/catalog/domo-force-sensing-humanoid-robot-manipulation-research/",
        "creator": "A. Edsinger-Gonzales, J. Weber",
        "description": " Humanoid robots found in research and commercial use today typically lack the ability to operate in unstructured and unknown environments. Force sensing and compliance at each robot joint can allow the robot to safely act in these environments. However, these features can be difficult to incorporate into robot designs. We present a new force sensing and compliant humanoid under development in the humanoid robotics group at MIT CSAIL. The robot, named Domo, is to be a research platform for exploring issues in general dexterous manipulation, visual perception, and learning. In this paper we describe aspects of the design, detail proposed research directions for the robot, and illustrate how the design of humanoid robots can be informed by the desired research goals.",
        "collectionName": "4th IEEE/RAS International Conference on Humanoid Robots, 2004.",
        "facets": {
            "provider": "mendeley",
            "year": "2004"
        }
    },
    {
        "id": "681e06ef-1db7-3a3a-b1c0-bcadd59b9b5f",
        "title": "Development of a new humanoid robot WABIAN-2",
        "uri": "http://www.mendeley.com/catalog/development-new-humanoid-robot-wabian2/",
        "eexcessURI": "http://www.mendeley.com/catalog/development-new-humanoid-robot-wabian2/",
        "creator": "Yu Ogura, Hiroyuki Aikawa, Kazushi Shimomura, Hideki Kondo, Akitoshi Morishima, Hun Ok Lim, Atsuo Takanishi",
        "description": "A new humanoid robot-WABIAN-2- that can be used as a human motion simulator is proposed in this paper. Its trunk is designed in order to permit rotation, and forward, backward, and sideway movement. Further, its arms are designed to support its complete weight when pushing a walk-assist machine. Moreover, it can lean on a walk-assist machine by forearm control using trunk motion. Basic walking experiments with WABIAN-2 are conducted with and without a walk-assist machine, thereby confirming its effectiveness",
        "collectionName": "Proceedings - IEEE International Conference on Robotics and Automation",
        "facets": {
            "provider": "mendeley",
            "year": "2006"
        }
    },
    {
        "id": "477c7ca1-298e-3d47-a3a7-21f9088bdeef",
        "title": "Robust real-time landmark recognition for humanoid robot navigation",
        "uri": "http://www.mendeley.com/catalog/robust-realtime-landmark-recognition-humanoid-robot-navigation/",
        "eexcessURI": "http://www.mendeley.com/catalog/robust-realtime-landmark-recognition-humanoid-robot-navigation/",
        "creator": "Mohammed Elmogy, Jianwei Zhang",
        "description": "Landmark recognition is identified as one important research area in robot navigation systems. It is a key feature for building robots capable of navigating and performing tasks in human environments. However, current object recognition research largely ignores the problems that the mobile robot context introduces. We developed a landmark recognition system which is used by a humanoid robot to identify landmarks during its navigation. The humanoid landmark recognition system is based on a two-step classification stage which is robust and invariant towards scaling and translations. Also, it provides a good balance between fast processing time and high detection accuracy. An appearance-based classification method is initially used to provide the rough initial estimate of the landmark. It is followed by a refinement step using a model-based method to estimate an accurate classification of the object. The goal of our work is to develop a rapid, robust object recognition system with a high detection rate that can actually be used by a humanoid robot to recognize landmarks during its navigation.",
        "collectionName": "2008 IEEE International Conference on Robotics and Biomimetics, ROBIO 2008",
        "facets": {
            "provider": "mendeley",
            "year": "2008"
        }
    },
    {
        "id": "5d5b990a-c698-34ac-a3eb-6b92244197a7",
        "title": "Vision-guided humanoid footstep planning for dynamic environments",
        "uri": "http://www.mendeley.com/catalog/visionguided-humanoid-footstep-planning-dynamic-environments/",
        "eexcessURI": "http://www.mendeley.com/catalog/visionguided-humanoid-footstep-planning-dynamic-environments/",
        "creator": "Philipp Michel, Joel Chestnutt, James Kuffner, Takeo Kanade",
        "description": "Despite the stable walking capabilities of modern biped humanoid robots, their ability to autonomously and safely navigate obstacle-filled, unpredictable environments has so far been limited. We present an approach to autonomous humanoid walking that combines vision-based sensing with a footstep planner, allowing the robot to navigate toward a desired goal position while avoiding obstacles. An environment map including the robot, goal, and obstacle locations is built in real-time from vision. The footstep planner then computes an optimal sequence of footstep locations within a time-limited planning horizon. Footstep plans are reused and only partially recomputed as the environment changes during the walking sequence. In our experiments, combining real-time vision with plan reuse has allowed a Honda ASIMO humanoid robot to autonomously traverse dynamic environments containing unpredictably moving obstacles",
        "collectionName": "Proceedings of 2005 5th IEEE-RAS International Conference on Humanoid Robots",
        "facets": {
            "provider": "mendeley",
            "year": "2005"
        }
    },
    {
        "id": "98338b71-c11b-3c11-8cc0-3ae8938b3148",
        "title": "Humanoid robots: A new kind of tool",
        "uri": "http://www.mendeley.com/catalog/humanoid-robots-new-kind-tool-1/",
        "eexcessURI": "http://www.mendeley.com/catalog/humanoid-robots-new-kind-tool-1/",
        "creator": "Bryan Adams, Cynthia Breazeal, Rodney A. Brooks, Brian Scassellati",
        "description": "Aside from their traditional roles, humanoid robots can be used to explore theories of human intelligence. The authors discuss their project aimed at developing robots that can behave like and interact with humans",
        "collectionName": "IEEE Intelligent Systems and Their Applications",
        "facets": {
            "provider": "mendeley",
            "year": "2000"
        }
    },
    {
        "id": "f5924a79-f750-34df-95c8-6dea4baa01ff",
        "title": "Towards cooperation of heterogeneous, autonomous robots: A case study of humanoid and wheeled robots",
        "uri": "http://www.mendeley.com/catalog/towards-cooperation-heterogeneous-autonomous-robots-case-study-humanoid-wheeled-robots/",
        "eexcessURI": "http://www.mendeley.com/catalog/towards-cooperation-heterogeneous-autonomous-robots-case-study-humanoid-wheeled-robots/",
        "creator": "Jutta Kiener, Oskar Von Stryk",
        "description": "In this paper a case study of the cooperation of a strongly heterogeneous autonomous robot team, composed of a highly articulated humanoid robot and a wheeled robot with largely complementing and some redundant abilities is presented. By combining strongly heterogeneous robots the diversity of achievable tasks increases as the variety of sensing and motion abilities of the robot system is extended, compared to a usually considered team of homogeneous robots. A number of methodologies and technologies required in order to achieve the long-term goal of cooperation of heterogeneous autonomous robots are discussed, including modeling tasks and robot abilities, task assignment and redistribution, robot behavior modeling and programming, robot middleware and robot simulation. Example solutions and their application to the cooperation of autonomous wheeled and humanoid robots are presented in this case study. The scenario describes a tightly coupled cooperative task, where the humanoid robot and the wheeled robot track a moving ball, which is to be approached and kicked by the humanoid robot into a goal. The task can be fulfilled successfully by combining the abilities of both robots. ?? 2010 Elsevier B.V. All rights reserved.",
        "collectionName": "Robotics and Autonomous Systems",
        "facets": {
            "provider": "mendeley",
            "year": "2010"
        }
    },
    {
        "id": "c656a765-310f-3904-bfed-108687a9b313",
        "title": "Can we talk to robots? Ten-month-old infants expected interactive humanoid robots to be talked to by persons",
        "uri": "http://www.mendeley.com/catalog/we-talk-robots-tenmonthold-infants-expected-interactive-humanoid-robots-talked-persons/",
        "eexcessURI": "http://www.mendeley.com/catalog/we-talk-robots-tenmonthold-infants-expected-interactive-humanoid-robots-talked-persons/",
        "creator": "Akiko Arita, Kazuo Hiraki, Takayuki Kanda, Hiroshi Ishiguro",
        "description": "As technology advances, many human-like robots are being developed. Although these humanoid robots should be classified as objects, they share many properties with human beings. This raises the question of how infants classify them. Based on the looking-time paradigm used by [Legerstee, M., Barna, J., & DiAdamo, C., (2000). Precursors to the development of intention at 6 months: understanding people and their actions. Developmental Psychology, 36, 5, 627-634.], we investigated whether 10-month-old infants expected people to talk to a humanoid robot. In a familiarization period, each infant observed an actor and an interactive robot behaving like a human, a non-interactive robot remaining stationary, and a non-interactive robot behaving like a human. In subsequent test trials, the infants were shown another actor talking to the robot and to the actor. We found that infants who had previously observed the interactive robot showed no difference in looking-time between the two types of test events. Infants in the other conditions, however, looked longer at the test event where the second experimenter talked to the robot rather than where the second experimenter talked to the person. These results suggest that infants interpret the interactive robot as a communicative agent and the non-interactive robot as an object. Our findings imply that infants categorize interactive humanoid robots as a kind of human being. ?? 2004 Elsevier B.V. All rights reserved.",
        "collectionName": "Cognition",
        "facets": {
            "provider": "mendeley",
            "year": "2005"
        }
    },
    {
        "id": "586b9b91-1460-3648-af3c-e03f802a2517",
        "title": "Methods and technologies for the implementation of large-scale robot tactile sensors",
        "uri": "http://www.mendeley.com/catalog/methods-technologies-implementation-largescale-robot-tactile-sensors/",
        "eexcessURI": "http://www.mendeley.com/catalog/methods-technologies-implementation-largescale-robot-tactile-sensors/",
        "creator": "Alexander Schmitz, Perla Maiolino, Marco Maggiali, Lorenzo Natale, Giorgio Cannata, Giorgio Metta",
        "description": "Even though the sense of touch is crucial for humans, most humanoid robots lack tactile sensing. While a large number of sensing technologies exist, it is not trivial to incorporate them into a robot. We have developed a compliant &#x201C;skin&#x201D; for humanoids that integrates a distributed pressure sensor based on capacitive technology. The skin is modular and can be deployed on nonflat surfaces. Each module scans locally a limited number of tactile-sensing elements and sends the data through a serial bus. This is a critical advantage as it reduces the number of wires. The resulting system is compact and has been successfully integrated into three different humanoid robots. We have performed tests that show that the sensor has favorable characteristics and implemented algorithms to compensate the hysteresis and drift of the sensor. Experiments with the humanoid robot iCub prove that the sensors can be used to grasp unmodeled, fragile objects.",
        "collectionName": "IEEE Transactions on Robotics",
        "facets": {
            "provider": "mendeley",
            "year": "2011"
        }
    },
    {
        "id": "edf23db6-dd8e-355a-8df1-7497567d5f67",
        "title": "Push recovery by stepping for humanoid robots with force controlled joints",
        "uri": "http://www.mendeley.com/catalog/push-recovery-stepping-humanoid-robots-force-controlled-joints/",
        "eexcessURI": "http://www.mendeley.com/catalog/push-recovery-stepping-humanoid-robots-force-controlled-joints/",
        "creator": "Benjamin J. Stephens, Christopher G. Atkeson",
        "description": "In order to interact with human environments, humanoid robots require safe and compliant control which can be achieved through force-controlled joints. In this paper, full body step recovery control for robots with force-controlled joints is achieved by adding model-based feed-forward controls. Push Recovery Model Predictive Control (PR-MPC) is presented as a method for generating full-body step recovery motions after a large disturbance. Results are presented from experiments on the Sarcos Primus humanoid robot that uses hydraulic actuators instrumented with force feedback control.",
        "collectionName": "2010 10th IEEE-RAS International Conference on Humanoid Robots, Humanoids 2010",
        "facets": {
            "provider": "mendeley",
            "year": "2010"
        }
    },
    {
        "id": "7abcda18-b9ef-38b9-83c5-4a34992c8610",
        "title": "Humanoid robot which can lift a 30kg box by whole body contact and tactile feedback",
        "uri": "http://www.mendeley.com/catalog/humanoid-robot-lift-30kg-box-whole-body-contact-tactile-feedback/",
        "eexcessURI": "http://www.mendeley.com/catalog/humanoid-robot-lift-30kg-box-whole-body-contact-tactile-feedback/",
        "creator": "Yoshiyuki Ohmura, Yasuo Kuniyoshi",
        "description": "We present realization of a humanoid which can lift a heavy object by whole body contact. Most humanoid motions are limited to the posture of the end-effectors only landing. In principle these humanoids can not do natural motion. If a humanoid robot is allowed arbitrary contact with the surrounding objects, it can improve the performance and operate a heavier object. We propose a \"whole body contact motion\" of a humanoid robot. It is defined as a control of contact state of a humanoid robot which has the distributed tactile sensors. We develop conformable and scalable tactile skin and an adult-size humanoid with a smooth surfaces for arbitrary contact. We install the skin on the entire surfaces of the humanoid. Finally we describe the humanoid lifting a 30kg box by tactile feedback.",
        "collectionName": "IEEE International Conference on Intelligent Robots and Systems",
        "facets": {
            "provider": "mendeley",
            "year": "2007"
        }
    },
    {
        "id": "b0003a25-a552-3466-ba24-24afa1518215",
        "title": "Mechanical design of humanoid robot platform KHR-3 (KAIST humanoid robot - 3: HUBO)",
        "uri": "http://www.mendeley.com/catalog/mechanical-design-humanoid-robot-platform-khr3-kaist-humanoid-robot-3-hubo/",
        "eexcessURI": "http://www.mendeley.com/catalog/mechanical-design-humanoid-robot-platform-khr3-kaist-humanoid-robot-3-hubo/",
        "creator": "Ill W. Park, Jung Y. Kim, Jungho Lee, Jun H. Oh",
        "description": "KHR-I has been developed on the purpose of research about biped walking. It has 21 DOF without hands and head, which has 12 DOF in legs, 1 DOF in torso, and 8 DOF in arms. The objective of KHR-2 (41 DOF) was to develop the humanoid which can walk on the living-floor with human-like appearance and movement. KHR-3 has the purpose that it has more human-like features, movements and human-friendly character. Mechanical design of KHR-3 is presented on this paper. The design concept, lower body design, upper body design and actuator selection of joints are included in this paper. We have developed and published KHR-I and 2 in last three years. KHR3 platform is based on KHR-2. It has 41 degree of freedom (DOF), 125 cm height, and 55 kg weight. The differences from KHR-2 are mechanical stiffness and detailed design of the frame in the mechanical point of view. Stiffness of the frame is increased and detailed design about joints and link frame has been modified or redesigned. We introduced exterior art design concept on KHR-2 in beginning, and the concept has been implemented on KHR-3 in mechanical design stage",
        "collectionName": "Proceedings of 2005 5th IEEE-RAS International Conference on Humanoid Robots",
        "facets": {
            "provider": "mendeley",
            "year": "2005"
        }
    },
    {
        "id": "807ffc6f-2186-3ff8-abc3-00e5c14bfbc1",
        "title": "Is imitation learning the route to humanoid robots?",
        "uri": "http://www.mendeley.com/catalog/imitation-learning-route-humanoid-robots/",
        "eexcessURI": "http://www.mendeley.com/catalog/imitation-learning-route-humanoid-robots/",
        "creator": "Stefan Schaal",
        "description": "This review investigates two recent developments in artificial intelligence and neural computation: learning from imitation and the development of humanoid robots. It is postulated that the study of imitation learning offers a promising route to gain new insights into mechanisms of perceptual motor control that could ultimately lead to the creation of autonomous humanoid robots. Imitation learning focuses on three important issues: efficient motor learning, the connection between action and perception, and modular motor control in the form of movement primitives. It is reviewed here how research on representations of, and functional connections between, action and perception have contributed to our understanding of motor acts of other beings. The recent discovery that some areas in the primate brain are active during both movement perception and execution has provided a hypothetical neural basis of imitation. Computational approaches to imitation learning are also described, initially from the perspective of traditional Al and robotics, but also from the perspective of neural network models and statistical-learning research. Parallels and differences between biological and computational approaches to imitation are highlighted and an overview of current projects that actually employ imitation learning for humanoid robots is given.",
        "collectionName": "Trends in Cognitive Sciences",
        "facets": {
            "provider": "mendeley",
            "year": "1999"
        }
    },
    {
        "id": "914d84c8-8fd8-39e9-9d25-7e7332325979",
        "title": "Footstep planning for the Honda ASIMO humanoid",
        "uri": "http://www.mendeley.com/catalog/footstep-planning-honda-asimo-humanoid/",
        "eexcessURI": "http://www.mendeley.com/catalog/footstep-planning-honda-asimo-humanoid/",
        "creator": "Joel Chestnutt, Manfred Lau, German Cheung, James Kuffner, Jessica Hodgins, Takeo Kanade",
        "description": "  Despite the recent achievements in stable dynamic walking for many humanoid robots, relatively little navigation autonomy has been achieved. In particular, the ability to autonomously select foot placement positions to avoid obstacles while walking is an important step towards improved navigation autonomy for humanoids. We present a footstep planner for the Honda ASIMO humanoid robot that plans a sequence of footstep positions to navigate toward a goal location while avoiding obstacles. The possible future foot placement positions are dependent on the current state of the robot. Using a finite set of state-dependent actions, we use an A* search to compute optimal sequences of footstep locations up to a time-limited planning horizon. We present experimental results demonstrating the robot navigating through both static and dynamic known environments that include obstacles moving on predictable trajectories. ",
        "collectionName": "Proceedings - IEEE International Conference on Robotics and Automation",
        "facets": {
            "provider": "mendeley",
            "year": "2005"
        }
    },
    {
        "id": "4b7acccc-07c5-3080-9822-a9d4a6718158",
        "title": "The eMOSAIC model for humanoid robot control",
        "uri": "http://www.mendeley.com/catalog/emosaic-model-humanoid-robot-control/",
        "eexcessURI": "http://www.mendeley.com/catalog/emosaic-model-humanoid-robot-control/",
        "creator": "Norikazu Sugimoto, Jun Morimoto, Sang Ho Hyon, Mitsuo Kawato",
        "description": "In this study, we propose an extension of the MOSAIC architecture to control real humanoid robots. MOSAIC was originally proposed by neuroscientists to understand the human ability of adaptive control. The modular architecture of the MOSAIC model can be useful for solving nonlinear and non-stationary control problems. Both humans and humanoid robots have nonlinear body dynamics and many degrees of freedom. Since they can interact with environments (e.g., carrying objects), control strategies need to deal with non-stationary dynamics. Therefore, MOSAIC has strong potential as a human motor-control model and a control framework for humanoid robots. Yet application of the MOSAIC model has been limited to simple simulated dynamics since it is susceptive to observation noise and also cannot be applied to partially observable systems. Our approach introduces state estimators into MOSAIC architecture to cope with real environments. By using an extended MOSAIC model, we are able to successfully generate squatting and object-carrying behaviors on a real humanoid robot. © 2012 Elsevier Ltd.",
        "collectionName": "Neural Networks",
        "facets": {
            "provider": "mendeley",
            "year": "2012"
        }
    },
    {
        "id": "afc7d880-3516-334a-beca-8d573d206f25",
        "title": "The development of Honda humanoid robot",
        "uri": "http://www.mendeley.com/catalog/development-honda-humanoid-robot/",
        "eexcessURI": "http://www.mendeley.com/catalog/development-honda-humanoid-robot/",
        "creator": "K. Hirai, M. Hirose, Y. Haikawa, T. Takenaka",
        "description": "In this paper, we present the mechanism, system configuration, basic control algorithm and integrated functions of the Honda humanoid robot. Like its human counterpart, this robot has the ability to move forward and backward, sideways to the right or the left, as well as diagonally. In addition, the robot can turn in any direction, walk up and down stairs continuously. Furthermore, due to its unique posture stability control, the robot is able to maintain its balance despite unexpected complications such as uneven ground surfaces. As a part of its integrated functions, this robot is able to move on a planned path autonomously and to perform simple operations via wireless teleoperation ",
        "collectionName": "Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146)",
        "facets": {
            "provider": "mendeley",
            "year": "1998"
        }
    }
]
